{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPA2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfNHAPxtc_DC"
      },
      "source": [
        "# Importing the required libraries\n",
        "import string\n",
        "import random\n",
        "import nltk\n",
        "import time\n",
        "import json\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROGpYPsCsp_m"
      },
      "source": [
        "# Mounting the gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwLrNbgctdsf"
      },
      "source": [
        "# Opening training and validation files.\n",
        "file_path = \"/content/gdrive/My Drive/CBT LM Dataset/train.txt\"\n",
        "json_path = \"/content/gdrive/My Drive/CBT LM Dataset/validation.jsonl\"\n",
        "comat_path = \"/content/blank.csv\"\n",
        "\n",
        "file = open(file_path,'r')\n",
        "text = file.read()\n",
        "file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nzOezC88ZkY"
      },
      "source": [
        "# Splitting the training files into sentences.\n",
        "sent = []\n",
        "for line in text.split('\\n'):\n",
        "  sent.append(line.translate(str.maketrans('', '', string.punctuation)).lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E95lMxTNy0uw"
      },
      "source": [
        "# All bigram models\n",
        "class bigramModel(object):\n",
        "  def __init__(self):\n",
        "    self.context = {}\n",
        "\n",
        "    # Co occurance matrix\n",
        "    self.bigram_counter = {}\n",
        "\n",
        "    # for the number of unique words\n",
        "    self.vocab = set()\n",
        "\n",
        "  # Added the function inside class\n",
        "  def calculateBigrams(self, tokens):\n",
        "    tokens = ['<START>'] + tokens\n",
        "    bigrams = [(tokens[i-1], tokens[i]) for i in range(1, len(tokens))]\n",
        "    return bigrams\n",
        "\n",
        "\n",
        "  # adding each sentence in the bigram model\n",
        "  def update(self, sentence):\n",
        "    \n",
        "    # tokenizing the sentence\n",
        "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "\n",
        "    # calculating the bigrams\n",
        "    bigrams = self.calculateBigrams(tokenize(sentence, tokenizer))\n",
        "\n",
        "    for bigram in bigrams:\n",
        "      prevWord, targetWord = bigram\n",
        "\n",
        "      # add the words in the vocab\n",
        "      self.vocab.add(prevWord)\n",
        "      self.vocab.add(targetWord)\n",
        "\n",
        "      # update in the co-occurance matrix (dictionary)\n",
        "      if prevWord in (self.bigram_counter.keys()):\n",
        "        if bigram in (self.bigram_counter[prevWord].keys()):\n",
        "          self.bigram_counter[prevWord][bigram] += 1.0\n",
        "        else:\n",
        "          self.bigram_counter[prevWord][bigram] = 1.0\n",
        "      else:\n",
        "        self.bigram_counter[prevWord] = {}\n",
        "        self.bigram_counter[prevWord][bigram] = 1.0\n",
        "      \n",
        "      if prevWord in self.context:\n",
        "        self.context[prevWord].append(targetWord)\n",
        "      else:\n",
        "        self.context[prevWord] = [targetWord]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1XHU4FuSs1_"
      },
      "source": [
        "# Return the word with maximum probabilty without smoothing\n",
        "def probabilitySimple(model, word, options):\n",
        "  maxi = -1\n",
        "  maxwd = \"\"\n",
        "  try:\n",
        "\n",
        "    # All the bigrams for the prevWord\n",
        "    countWord = model.bigram_counter[word]\n",
        "    sumWord = 0\n",
        "\n",
        "    # total count of occurance for prevWord\n",
        "    for count_x in countWord.values():\n",
        "      sumWord += count_x\n",
        "    \n",
        "    # For all options in the list\n",
        "    for option in options:\n",
        "      try:\n",
        "\n",
        "        # check the probability\n",
        "        if countWord[(word, option)] / sumWord > maxi:\n",
        "          maxi = countWord[(word, option)] / sumWord\n",
        "          maxwd = option\n",
        "      except KeyError:\n",
        "        pass\n",
        "  except KeyError:\n",
        "    pass\n",
        "  return maxwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y56dZv8gy9KR"
      },
      "source": [
        "# Add 1 smoothing\n",
        "def probibilityLaplace(model, context, token):\n",
        "  try:\n",
        "\n",
        "    # Add the count(word) + count(unique words in vocabulary)\n",
        "    count_of_context = float(len(model.context[context]) + len(model.vocab)) \n",
        "    try:\n",
        "\n",
        "      # add 1 for all words\n",
        "      count_of_token = model.bigram_counter[context][(context, token)] + 1\n",
        "      result = count_of_token / count_of_context\n",
        "\n",
        "    except KeyError:\n",
        "\n",
        "      # word is not present in the training set\n",
        "      result = 1 / count_of_context\n",
        "    return result\n",
        "  except:\n",
        "    return -1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzl6i8gsS1_h"
      },
      "source": [
        "# Add K smoothing. We need to provide k using the dev set (0 < k < 1)\n",
        "def probibilityAddK(model, context, token, k):\n",
        "  try:\n",
        "\n",
        "    # Add the count(word) + count(unique words in vocabulary)\n",
        "    count_of_context = float(len(model.context[context]) + len(model.vocab)) + k*(len(model.vocab))\n",
        "    try:\n",
        "\n",
        "      # add k for all words\n",
        "      count_of_token = model.bigram_counter[context][(context, token)] + k\n",
        "      result = count_of_token / count_of_context\n",
        "\n",
        "    except KeyError:\n",
        "\n",
        "      # word not present in the training data\n",
        "      result = k / count_of_context \n",
        "    return result\n",
        "  except:\n",
        "    return -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo8u8XW_95DW"
      },
      "source": [
        "def callbigramModel(sentences):\n",
        "    # Make a model\n",
        "    model = bigramModel()\n",
        "\n",
        "    # add each sentence in the training data\n",
        "    for sentence in sentences:\n",
        "      model.update(sentence)\n",
        "    return model\n",
        "\n",
        "# Tokenize the sentence.\n",
        "def tokenize(sentence, tokenizer):\n",
        "  sentence = sentence.lower()\n",
        "  return tokenizer.tokenize(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRLOV0zw0dX4"
      },
      "source": [
        "# check the previous word and call the required function\n",
        "def returnMaskedWord(model, sentence, options, smoothing = \"None\"):\n",
        "  prevs = ['<START>']\n",
        "\n",
        "  # Split the sentence and check all the words\n",
        "  for word in sentence.split():\n",
        "    if word == 'XXXXX':\n",
        "\n",
        "      # check against the options\n",
        "      ans = findMaskedWord(model, prevs[-1], options, smoothing)\n",
        "      if ans == \"\":\n",
        "        ans = options[-1]\n",
        "      return ans\n",
        "    prevs.append(word)\n",
        "\n",
        "  # return the last word if the probability is 0 for all\n",
        "  return options[-1]\n",
        "\n",
        "def findMaskedWord(mod, word, options, smoothing):\n",
        "  maxi = 0\n",
        "  maxwd = \"\"\n",
        "\n",
        "  # Check the smoothing option\n",
        "  for option in options:\n",
        "    if smoothing == \"AddK\":\n",
        "      probX = probibilityAddK(model, word, option, 0.2) #Provide the appropriete value of k.\n",
        "\n",
        "    elif smoothing == \"Laplace\":\n",
        "      probX = probibilityLaplace(model, word, option)\n",
        "    \n",
        "    else:\n",
        "      return probabilitySimple(model, word, options)\n",
        "\n",
        "    # If the probability is maximum, then return the word\n",
        "    if probX > maxi:\n",
        "      maxi = probX\n",
        "      maxwd = option\n",
        "\n",
        "  return maxwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNaQ3v-iRMBc"
      },
      "source": [
        "Calling the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3gYN24Dk4Rz"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "# Training the model\n",
        "model = callbigramModel(sent)\n",
        "print(\"Bigram model Trained\")\n",
        "print (\"Time taken to create the model:\", {time.time() - start})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9-qoDh09RKo"
      },
      "source": [
        "# Adding the testing data\n",
        "test_sents = []\n",
        "for line in open(json_path, 'r'):\n",
        "  test_sents.append(json.loads(line))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XATUS5ymXdtK"
      },
      "source": [
        "Accuracy of The Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO-MG2jJAYsr"
      },
      "source": [
        "# File printing function\n",
        "def printToFile(f, sentence, testops, pred):\n",
        "  f.write(sentence)\n",
        "  f.write(\"\\n\")\n",
        "  f.write(str(testops))\n",
        "  f.write('\\n')\n",
        "  f.write(pred)\n",
        "  f.write('\\n')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INuDMjK2bvrJ"
      },
      "source": [
        "# Calculate the accuracy for the without smoothing method\n",
        "# f = open(\"output1.txt\", \"w\")\n",
        "correctWord = 0\n",
        "totalWords = 0\n",
        "\n",
        "for test in test_sents:\n",
        "  \n",
        "  sentence = test['question'].translate(str.maketrans('', '', string.punctuation))\n",
        "  pred = returnMaskedWord(model, sentence, test['options'], \"None\") #Predict using the smoothing\n",
        "\n",
        "  # printToFile(f, sentence, test['options'], pred)\n",
        "\n",
        "  if pred == test['answer']:\n",
        "    correctWord += 1\n",
        "  totalWords += 1\n",
        "# f.close()\n",
        "print(\"The accuracy of the bigram model wihout smoothing is: \", correctWord * 100 / totalWords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuF7x3CM1pPS"
      },
      "source": [
        "# Calculate the accuracy for the Laplace method\n",
        "# f = open(\"outputLaplace.txt\", \"w\")\n",
        "correctWord = 0\n",
        "totalWords = 0\n",
        "\n",
        "for test in test_sents:\n",
        "\n",
        "  s = test['question'].translate(str.maketrans('', '', string.punctuation))\n",
        "  pred = returnMaskedWord(model, s, test['options'], \"Laplace\")\n",
        "\n",
        "  #printToFile(f, sentence, test['options'], pred)\n",
        "\n",
        "  if pred == test['answer']:\n",
        "    correctWord += 1\n",
        "  totalWords += 1\n",
        "# f.close()\n",
        "print(\"The accuracy of the bigram model with Laplace smoothing is: \", correctWord * 100 / totalWords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbKbHn9X1lvS"
      },
      "source": [
        "# Calculate the accuracy for the Add K method\n",
        "# f = open(\"outputAddK.txt\", \"w\")\n",
        "\n",
        "correctWord = 0\n",
        "totalWords = 0\n",
        "for test in test_sents:\n",
        "\n",
        "  s = test['question'].translate(str.maketrans('', '', string.punctuation))\n",
        "  pred = returnMaskedWord(model, s, test['options'], \"AddK\")\n",
        "\n",
        "  #printToFile(f, sentence, test['options'], pred)\n",
        "  \n",
        "  if pred == test['answer']:\n",
        "    correctWord += 1\n",
        "  totalWords += 1\n",
        "\n",
        "# f.close()\n",
        "\n",
        "print(\"The accuracy of the bigram model with Add k smoothing is: \", correctWord * 100 / totalWords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q47hvFM2O3U"
      },
      "source": [
        "### Bonus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPBDSh0o49oh"
      },
      "source": [
        "# Without smoothing\n",
        "def probabilitySimpleFuture(model, prevWord, nextWord, options):\n",
        "  maxi = -1\n",
        "  maxwd = \"\"\n",
        "  \n",
        "  try:\n",
        "\n",
        "    # Calculate the count of prevWord\n",
        "    countWord = model.bigram_counter[prevWord]\n",
        "    sumX = 0\n",
        "    for x in countWord.values():\n",
        "      sumX += x\n",
        "\n",
        "    for opt in options:\n",
        "      try:\n",
        "\n",
        "        # Probabilty of option given word\n",
        "        wordProb = (countWord[(prevWord,opt)] / sumX)\n",
        "\n",
        "        # Probability of next word given option\n",
        "        if (nextWord != \"Null\"):\n",
        "          countOption = model.bigram_counter[opt]\n",
        "          sumOpt = 0\n",
        "          for x in countOption.values():\n",
        "            sumOpt += x\n",
        "\n",
        "          wordProb = (countWord[(prevWord,opt)] / sumX) * (countOption[(opt, nextWord)] / sumOpt) if sumOpt > 0 else (countWord[(prevWord , opt)] / sumX)\n",
        "\n",
        "        # Word with maximum probability\n",
        "        if wordProb > maxi:\n",
        "          maxi = wordProb\n",
        "          maxwd = opt\n",
        "      except KeyError:\n",
        "        pass\n",
        "  except KeyError:\n",
        "    pass\n",
        "  return maxwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOYw7E-TG9UH"
      },
      "source": [
        "# Return the masked word choice using the smoothing option\n",
        "def findMaskedWordFuture(model, word, nextWord, options, smoothing):\n",
        "  maxi = 0\n",
        "  maxwd = \"\"\n",
        "  for opt in options:\n",
        "\n",
        "    # Add k\n",
        "    if smoothing == \"AddK\":\n",
        "      x = probibilityAddK(model, word, opt, 0.00001)\n",
        "\n",
        "      # Probability with the next word\n",
        "      y = probibilityAddK(model, opt, nextWord, 0.00001)\n",
        "\n",
        "    elif smoothing ==\"Laplace\":\n",
        "      x = probibilityLaplace(model, word, opt) \n",
        "      y = probibilityLaplace(model, opt, nextWord)\n",
        "\n",
        "    else:\n",
        "      return probabilitySimpleFuture(model, word, nextWord, options)\n",
        "\n",
        "    if x*y > maxi:\n",
        "      maxi = x*y\n",
        "      maxwd = opt\n",
        "\n",
        "  # Return the word\n",
        "  return maxwd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9t7rjHE8yjS"
      },
      "source": [
        "def returnMaskedWordFuture(model, sentence, options, smoothing):\n",
        "  prevs = ['<START>']\n",
        "\n",
        "  # Split the sentence\n",
        "  tokens = sentence.split()\n",
        "\n",
        "  # check the masked word\n",
        "  for word in tokens:\n",
        "    if word == 'XXXXX':\n",
        "      futureContextindex  = tokens.index(word)\n",
        "      futureContext = tokens[futureContextindex + 1] if (futureContextindex < len(tokens) - 1) else \"Null\"\n",
        "      \n",
        "      # check the smoothing method\n",
        "      ans = findMaskedWordFuture(model, prevs[-1], futureContext, options, smoothing)\n",
        "      \n",
        "      if ans == \"\":\n",
        "        ans = options[-1]\n",
        "      return ans\n",
        "    prevs.append(word)\n",
        "\n",
        "  # Return the last word in case of no solution\n",
        "  return options[-1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug14LTkqMOsI"
      },
      "source": [
        "# No smoothing\n",
        "# f = open(\"NoSmoothingBothSides.txt\", \"w\")\n",
        "correctWord = 0\n",
        "totalWords = 0\n",
        "\n",
        "for test in test_sents:\n",
        "\n",
        "  s = test['question'].translate(str.maketrans('', '', string.punctuation))\n",
        "  pred = returnMaskedWordFuture(model, s, test['options'], \"None\")\n",
        "\n",
        "  #printToFile(f, sentence, test['options'], pred)\n",
        "\n",
        "  if pred == test['answer']:\n",
        "    correctWord += 1\n",
        "  totalWords += 1\n",
        "\n",
        "# f.close()  \n",
        "\n",
        "print(\"The accuracy of model without smoothing: \", correctWord * 100 / totalWords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgEP0n6FImBa"
      },
      "source": [
        "# Laplace Method\n",
        "# f = open(\"LaplaceBothSides.txt\", \"w\")\n",
        "correctWord = 0\n",
        "totalWords = 0\n",
        "\n",
        "for test in test_sents:\n",
        "\n",
        "  s = test['question'].translate(str.maketrans('', '', string.punctuation))\n",
        "  pred = returnMaskedWordFuture(model, s, test['options'], \"Laplace\")\n",
        "\n",
        "  #printToFile(f, sentence, test['options'], pred)\n",
        "\n",
        "  if pred == test['answer']:\n",
        "    correctWord += 1\n",
        "  totalWords += 1\n",
        "\n",
        "# f.close()    \n",
        "\n",
        "print(\"The accuracy of model with Laplace Method: \", correctWord*100/totalWords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZPkk9bMHQZy"
      },
      "source": [
        "# Add K method\n",
        "# f = open(\"AddKBothSides.txt\", \"w\")\n",
        "\n",
        "correctWord = 0\n",
        "totalWords = 0\n",
        "for test in test_sents:\n",
        "\n",
        "  s = test['question'].translate(str.maketrans('', '', string.punctuation))\n",
        "  pred = returnMaskedWordFuture(model, s, test['options'], \"AddK\")\n",
        "\n",
        "  #printToFile(f, sentence, test['options'], pred)\n",
        "\n",
        "  if pred == test['answer']:\n",
        "    correctWord += 1\n",
        "\n",
        "  totalWords += 1\n",
        "\n",
        "# f.close()    \n",
        "\n",
        "print(\"The accuracy of model with Add k method: \", correctWord * 100 / totalWords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrWmKZ3HEeJt"
      },
      "source": [
        "### Instance of Co-occurence matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1JXO4uPBwx6"
      },
      "source": [
        "def tokenize(sentence, tokenizer):\n",
        "  sentence = sentence.lower()\n",
        "  return tokenizer.tokenize(sentence)\n",
        "  \n",
        "def calculateBigrams(tokens):\n",
        "    n = 2\n",
        "    tokens = 1*['<START>']+tokens\n",
        "    l = [(tokens[i-1], tokens[i]) for i in range(1, len(tokens))]\n",
        "    return l\n",
        "\n",
        "def callbigramModel(sentences):\n",
        "    model = bigramModel()\n",
        "    for sentence in sent:\n",
        "      model.update(sentence)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNjOH00SE1ox"
      },
      "source": [
        "# simple bigram model\n",
        "class bigramModel2(object):\n",
        "  def __init__(self):\n",
        "    self.context = {}\n",
        "    self.bigram_counter = {}\n",
        "    self.wd_to_idx = {}\n",
        "    self.ct=0\n",
        "\n",
        "\n",
        "  def update(self, sentence):\n",
        "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "    bigrams = calculateBigrams(tokenize(sentence, tokenizer))\n",
        "    for bigram in bigrams:\n",
        "      prevWord, targetWord = bigram\n",
        "      if prevWord in (self.bigram_counter.keys()):\n",
        "\n",
        "        if bigram in (self.bigram_counter[prevWord].keys()):\n",
        "          self.bigram_counter[prevWord][bigram] += 1.0\n",
        "        else:\n",
        "          self.bigram_counter[prevWord][bigram] = 1.0\n",
        "      else:\n",
        "        self.bigram_counter[prevWord]={}\n",
        "        self.bigram_counter[prevWord][bigram] = 1.0\n",
        "      \n",
        "      prevWord, targetWord = bigram\n",
        "      if prevWord in self.context:\n",
        "        self.context[prevWord].append(targetWord)\n",
        "      else:\n",
        "        self.context[prevWord] = [targetWord]\n",
        "      if prevWord not in self.wd_to_idx.keys():\n",
        "        self.wd_to_idx[prevWord]=self.ct\n",
        "        self.ct+=1\n",
        "      if targetWord not in self.wd_to_idx.keys():\n",
        "        self.wd_to_idx[targetWord]=self.ct\n",
        "        self.ct+=1\n",
        "\n",
        "  \n",
        "  def prob(self, context, token):\n",
        "      try:\n",
        "        count_of_token = self.bigram_counter[(context, token)]\n",
        "        count_of_context = float(len(self.context[context]))\n",
        "        result = count_of_token / count_of_context\n",
        "\n",
        "      except KeyError:\n",
        "        result = 0.0\n",
        "      return result\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7b9cf1BE_mo"
      },
      "source": [
        "# Co occurance matrix\n",
        "# Uses a lot of space\n",
        "def co_mat(mod):\n",
        "  vocab_size = len(mod.wd_to_idx)\n",
        "  file = open(comat_path, 'w')\n",
        "\n",
        "  for word,idx in mod.wd_to_idx.items():\n",
        "    comat = np.zeros(vocab_size)\n",
        "    try:\n",
        "      for val in set(mod.context[word]):\n",
        "        j = mod.wd_to_idx[val]\n",
        "        comat[j]+=1\n",
        "    except KeyError:\n",
        "      pass\n",
        "\n",
        "    sum_vec = np.sum(comat)\n",
        "\n",
        "    if sum_vec != 0:\n",
        "      comat = comat/sum_vec\n",
        "\n",
        "    np.savetxt(file,comat, newline=\", \")\n",
        "    file.write(\"\\n\")\n",
        "\n",
        "  file.close()\n",
        "\n",
        "co_mat(mod)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}