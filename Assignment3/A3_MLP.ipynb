{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3_MLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8kl1PDiFxgo"
      },
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "nltk.download('punkt')\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import gensim.downloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz-Lo5LWC12n"
      },
      "source": [
        "word_vectors = gensim.downloader.load('word2vec-google-news-300')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueVHJK6jC7YG"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxVzzC7NGa2_"
      },
      "source": [
        "# Mounting the gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02Px05zaHqZ8"
      },
      "source": [
        "# Opening training files.\n",
        "file_path = \"/content/gdrive/MyDrive/Brown_POS Dataset/Brown_tagged_train.txt\"\n",
        "# json_path = \"/content/a03_test.txt\"\n",
        "\n",
        "file = open(file_path,'r')\n",
        "text = file.read()\n",
        "file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlThdxhxJbt3"
      },
      "source": [
        "def get_data(path):\n",
        "    \n",
        "    file = open(file_path,'r')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "\n",
        "    sent = []\n",
        "    for line in text.split('\\n'):\n",
        "        sent.append(line)\n",
        "\n",
        "    text = []\n",
        "    labels = []\n",
        "\n",
        "    for sentence in sent:\n",
        "        sentence = sentence.strip()\n",
        "        words = sentence.split(\" \")\n",
        "        \n",
        "        for word in words:\n",
        "            s_index = word.rfind(\"/\")\n",
        "            sen_word = (word[:s_index]).lower()\n",
        "            label = word[s_index + 1:]\n",
        "            text.append(sen_word)\n",
        "            labels.append(label)\n",
        "            # print(word, label)\n",
        "    \n",
        "    return text, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpai_FnjJd3t"
      },
      "source": [
        "# Separating the words and labels\n",
        "words, tags = get_data(file_path)\n",
        "words = [words]\n",
        "labels = set(tags)\n",
        "\n",
        "# print(labels)\n",
        "# word_list = {}\n",
        "\n",
        "\n",
        "# for tag in tags:\n",
        "#     if tag in word_list.keys():\n",
        "#         word_list[tag] += 1\n",
        "\n",
        "#     else:\n",
        "#         word_list[tag] = 1\n",
        "    \n",
        "\n",
        "# print(word_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd0QigzPTzvp"
      },
      "source": [
        "# Label Encoder\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(tags)\n",
        "y = to_categorical(y, len(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xHUEfxGQLtI"
      },
      "source": [
        "def checkWord(word):\n",
        "    tokenizer = RegexpTokenizer('\\w+')\n",
        "    words = tokenizer.tokenize(word)\n",
        "    return words\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av_EsagwTs8f"
      },
      "source": [
        "m,n = np.shape(words)\n",
        "X_w2v = []\n",
        "for i in range(n):\n",
        "    try:\n",
        "        vec = word_vectors.wv[words[0][i]]\n",
        "    except KeyError:\n",
        "         vec = np.random.randn(300)*(0.01)\n",
        "\n",
        "    X_w2v.append(vec)\n",
        "\n",
        "feature_len = len(X_w2v[0])\n",
        "num_classes = len(labels)\n",
        "input_shape = (feature_len,)\n",
        "y = np.array(y)\n",
        "X_w2v = np.array(X_w2v)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOql-whQzKOt"
      },
      "source": [
        "# Making the model\n",
        "model = Sequential()\n",
        "model.add(Dense(350, input_shape = input_shape, activation='relu'))\n",
        "model.add(Dense(50, activation = 'relu'))\n",
        "model.add(Dense(num_classes, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiE5yDoBT1-C"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_w2v, y, test_size = 0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X8nnUnHzCoO"
      },
      "source": [
        "# Training the model\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.fit(X_train, y_train, epochs = 10, batch_size = 200)\n",
        "test_results = model.evaluate(X_test, y_test)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
        "\n",
        "# y_pred = model.predict(X_test)\n",
        "# y_pred = np.argmax(y_pred, axis = 1)\n",
        "# y_pred = le.inverse_transform(y_pred)\n",
        "# y_pred_dict = {}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjclEBKS3G6R"
      },
      "source": [
        "# y_test_new = le.inverse_transform(y_test)\n",
        "# red_word_list = {}\n",
        "# for i in range(len(y_test)):\n",
        "#     if (y_pred[i] != y_test_new[i]):\n",
        "#         print(\"yes\")\n",
        "#         if (y_test_new[i] in red_word_list.keys()):\n",
        "#             red_word_list[y_test_new[i]] += 1\n",
        "#         else:\n",
        "#             red_word_list[y_test_new[i]] = 1\n",
        "\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJX1VDzV2N9v"
      },
      "source": [
        "# # red_word_list = word_list\n",
        "# print(red_word_list)\n",
        "# print(word_list)\n",
        "# print(y_pred)\n",
        "\n",
        "# toPlot = {}\n",
        "# for key, value in word_list.items():\n",
        "#     val = red_word_list.get(key)\n",
        "#     if val:\n",
        "#         toPlot[key] = val/value\n",
        "#     else:\n",
        "#         toPlot[key] = 0\n",
        "\n",
        "# print(toPlot)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVxWNFka7T4_"
      },
      "source": [
        "# plt.bar(range(len(toPlot)), list(toPlot.values()), align='center', width = 0.4)\n",
        "# plt.xticks(range(len(toPlot)), list(toPlot.keys()))\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFggdDMRnP6c"
      },
      "source": [
        "# Loss function without one hot encoding\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.fit(X_train, y_train, epochs = 20, batch_size = 200)\n",
        "test_results = model.evaluate(X_test, y_test)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF_jlAd4CRgQ"
      },
      "source": [
        "# Glove\n",
        "def checkWord(word):\n",
        "    tokenizer = RegexpTokenizer('\\w+')\n",
        "    words = tokenizer.tokenize(word)\n",
        "    return words\n",
        "\n",
        "\n",
        "embeddings_index = dict()\n",
        "f = open('/content/glove.6B.300d.txt')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWY5w4uIFy_r"
      },
      "source": [
        "model_g = []\n",
        "for i in words[0]:\n",
        "    if embeddings_index.get(i) is not None:\n",
        "        model_g.append(embeddings_index.get(i))\n",
        "    else:\n",
        "\n",
        "        words_new = checkWord(i)\n",
        "        val = [1]*(300)\n",
        "        \n",
        "        for each_word in words_new:\n",
        "            if embeddings_index.get(each_word) is not None:\n",
        "                val = np.multiply(val, embeddings_index.get(each_word))\n",
        "\n",
        "        if (max(val) == 1 and min(val) == 1):\n",
        "            val = np.random.randn(300)*(0.01)\n",
        "\n",
        "        model_g.append(val)\n",
        "\n",
        "y = np.array(y)\n",
        "X_g = np.array(model_g)\n",
        "\n",
        "feature_len = len(X_g[0])\n",
        "input_shape = (feature_len,)\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rc6ptdOSf5K"
      },
      "source": [
        "# Label Encoder\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(tags)\n",
        "y = to_categorical(y, len(labels) )\n",
        "\n",
        "num_classes = len(labels)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t__jDnyFsRHG"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(350, input_shape = input_shape, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(num_classes, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7DE_Vl9W2ud"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_g, y, test_size = 0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhQI2KDjW34C"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.fit(X_train, y_train, epochs = 10, batch_size = 200, verbose = 1)\n",
        "test_results = model.evaluate(X_test, y_test, verbose = 1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
        "\n",
        "\n",
        "# y_pred = model.predict(X_test)\n",
        "# y_pred = np.argmax(y_pred, axis = 1)\n",
        "# y_pred = le.inverse_transform(y_pred)\n",
        "\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU-Z3slz8yPF"
      },
      "source": [
        "# y_test_new = np.argmax(y_test, axis = 1)\n",
        "# y_test_new = le.inverse_transform(y_test_new)\n",
        "# red_word_list = {}\n",
        "# for i in range(len(y_test_new)):\n",
        "#     if (y_test_new[i] != y_pred[i]):\n",
        "#         if (y_test_new[i] in red_word_list.keys()):\n",
        "#             red_word_list[y_test_new[i]] += 1\n",
        "#         else:\n",
        "#             red_word_list[y_test_new[i]] = 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e56sYFJp8QSO"
      },
      "source": [
        "# # red_word_list = word_list\n",
        "# print(red_word_list)\n",
        "# print(word_list)\n",
        "# print(y_pred)\n",
        "\n",
        "# toPlot = {}\n",
        "# for key, value in word_list.items():\n",
        "#     val = red_word_list.get(key)\n",
        "#     if val:\n",
        "#         toPlot[key] = val/value\n",
        "#     else:\n",
        "#         toPlot[key] = 0\n",
        "\n",
        "# print(toPlot)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n21M_6Zq9O25"
      },
      "source": [
        "# plt.bar(range(len(toPlot)), list(toPlot.values()), align='center', width = 0.4)\n",
        "# plt.xticks(range(len(toPlot)), list(toPlot.keys()))\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScW2K53DpFsO"
      },
      "source": [
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.fit(X_train, y_train, epochs = 20, batch_size = 200)\n",
        "test_results = model.evaluate(X_test, y_test)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nna_fmYWfaW"
      },
      "source": [
        "# Epochs for glove and word2vec\n",
        "acc_w2v = []\n",
        "acc_g = []\n",
        "\n",
        "num_epochs = [5, 10, 15, 20, 30]\n",
        "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_w2v, y, test_size = 0.20)\n",
        "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(X_g, y, test_size = 0.20)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(350, input_shape = input_shape, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(num_classes, activation = 'softmax'))\n",
        "\n",
        "for i in range(len(num_epochs)):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(350, input_shape = input_shape, activation='relu'))\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "    model.fit(X_train_w2v, y_train_w2v, epochs = num_epochs[i], batch_size = 200)\n",
        "    test_results = model.evaluate(X_test_w2v, y_test_w2v)\n",
        "    acc_w2v.append(test_results[1])\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(350, input_shape = input_shape, activation='relu'))\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "    \n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "    model.fit(X_train_g, y_train_g, epochs = num_epochs[i], batch_size = 200)\n",
        "    test_results = model.evaluate(X_test_g, y_test_g)\n",
        "    acc_g.append(test_results[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2gUWUULahXV"
      },
      "source": [
        "plt.plot(num_epochs, acc_w2v, color = \"red\", label = \"Word 2 Vec\")\n",
        "plt.plot(num_epochs, acc_g, color = \"blue\", label = \"Glove\")\n",
        "plt.title(\"Accuracy with epochs\")\n",
        "plt.xlabel(\"Number of epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3s_01yUeJYP"
      },
      "source": [
        "# Activation Functions for glove and word2vec\n",
        "acc_w2v = []\n",
        "acc_g = []\n",
        "\n",
        "act_funcs = [\"relu\", \"sigmoid\", \"tanh\", \"selu\"]\n",
        "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_w2v, y, test_size = 0.20)\n",
        "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(X_g, y, test_size = 0.20)\n",
        "\n",
        "\n",
        "for i in range(len(act_funcs)):\n",
        "        \n",
        "    model = Sequential()\n",
        "    model.add(Dense(350, input_shape = input_shape, activation = act_funcs[i]))\n",
        "    model.add(Dense(50, activation = act_funcs[i]))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "    \n",
        "    \n",
        "    # Word 2 vec\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "    model.fit(X_train_w2v, y_train_w2v, epochs = 30, batch_size = 200)\n",
        "    test_results = model.evaluate(X_test_w2v, y_test_w2v)\n",
        "    acc_w2v.append(test_results[1])\n",
        "\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(350, input_shape = input_shape, activation = act_funcs[i]))\n",
        "    model.add(Dense(50, activation = act_funcs[i]))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "    \n",
        "    # Glove\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "    model.fit(X_train_g, y_train_g, epochs = 30, batch_size = 200)\n",
        "    test_results = model.evaluate(X_test_g, y_test_g)\n",
        "    acc_g.append(test_results[1])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8JEp-z3zeSy"
      },
      "source": [
        "\n",
        "plt.plot(act_funcs, acc_w2v, color = \"red\", label = \"Word 2 Vec\")\n",
        "plt.plot(act_funcs, acc_g, color = \"blue\", label = \"Glove\")\n",
        "plt.title(\"Accuracy with activation functions\")\n",
        "plt.xlabel(\"Activation functions\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpHomILxrBzZ"
      },
      "source": [
        "# Optimizers for glove and word2vec\n",
        "acc_w2v = []\n",
        "acc_g = []\n",
        "\n",
        "opt = [\"adam\", \"RMSprop\", \"sgd\", \"adagrad\"]\n",
        "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_w2v, y, test_size = 0.20)\n",
        "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(X_g, y, test_size = 0.20)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(opt)):\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(350, input_shape = input_shape, activation = \"relu\"))\n",
        "    model.add(Dense(50, activation = \"relu\" ))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "        \n",
        "    \n",
        "    \n",
        "    # Word 2 vec\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = opt[i] , metrics = ['accuracy'])\n",
        "    model.fit(X_train_w2v, y_train_w2v, epochs = 15, batch_size = 200)\n",
        "    test_results = model.evaluate(X_test_w2v, y_test_w2v)\n",
        "    acc_w2v.append(test_results[1])\n",
        "\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(350, input_shape = input_shape, activation = \"relu\"))\n",
        "    model.add(Dense(50, activation =\"relu\" ))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "    \n",
        "    # Glove\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = opt[i], metrics = ['accuracy'])\n",
        "    model.fit(X_train_g, y_train_g, epochs = 15, batch_size = 200)\n",
        "    test_results = model.evaluate(X_test_g, y_test_g)\n",
        "    acc_g.append(test_results[1])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrnFo6Luz534"
      },
      "source": [
        "plt.plot(opt, acc_w2v, color = \"red\", label = \"Word 2 Vec\")\n",
        "plt.plot(opt, acc_g, color = \"blue\", label = \"Glove\")\n",
        "plt.title(\"Accuracy with Optimizers\")\n",
        "plt.xlabel(\"Optimizers\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oscCCkZfGCB"
      },
      "source": [
        "# Layer 1 for glove and word2vec\n",
        "acc_w2v = []\n",
        "acc_g = []\n",
        "\n",
        "num_layer1 = [100, 200, 300, 400]\n",
        "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_w2v, y, test_size = 0.20)\n",
        "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(X_g, y, test_size = 0.20)\n",
        "\n",
        "\n",
        "for i in range(len(num_layer1)):\n",
        "        \n",
        "    model = Sequential()\n",
        "    model.add(Dense(num_layer1[i], input_shape = input_shape, activation = \"relu\"))\n",
        "    model.add(Dense(50, activation = \"relu\" ))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "    \n",
        "    \n",
        "    # Word 2 vec\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'RMSprop', metrics = ['accuracy'])\n",
        "    model.fit(X_train_w2v, y_train_w2v, epochs = 15, batch_size = 200)\n",
        "    test_results = model.evaluate(X_test_w2v, y_test_w2v)\n",
        "    acc_w2v.append(test_results[1])\n",
        "    \n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(num_layer1[i], input_shape = input_shape, activation = \"relu\"))\n",
        "    model.add(Dense(50, activation = \"relu\"))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "\n",
        "    # Glove\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'RMSprop', metrics = ['accuracy'])\n",
        "    model.fit(X_train_g, y_train_g, epochs = 15, batch_size = 200)\n",
        "    test_results = model.evaluate(X_test_g, y_test_g)\n",
        "    acc_g.append(test_results[1])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8kW-7YZ5SFu"
      },
      "source": [
        "\n",
        "plt.plot(num_layer1, acc_w2v, color = \"red\", label = \"Word 2 Vec\")\n",
        "plt.plot(num_layer1, acc_g, color = \"blue\", label = \"Glove\")\n",
        "plt.title(\"Accuracy with layer 1 size\")\n",
        "plt.xlabel(\"Layer 1 sizes\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P02uzMQ7qkBX"
      },
      "source": [
        "# Layer 2 for glove and word2vec\n",
        "acc_w2v = []\n",
        "acc_g = []\n",
        "\n",
        "num_layer2 = [20, 30, 50, 100]\n",
        "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_w2v, y, test_size = 0.20)\n",
        "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(X_g, y, test_size = 0.20)\n",
        "\n",
        "\n",
        "for i in range(len(acc_funcs)):\n",
        "        \n",
        "    model = Sequential()\n",
        "    model.add(Dense(350, input_shape = input_shape, activation = \"relu\" ))\n",
        "    model.add(Dense(num_layer2[i], activation = \"relu\"))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "    \n",
        "    \n",
        "    # Word 2 vec\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "    model.fit(X_train_w2v, y_train_w2v, epochs = 15, batch_size = 200)\n",
        "    test_results = model.evaluate(X_test_w2v, y_test_w2v)\n",
        "    acc_w2v.append(test_results[1])\n",
        "\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(num_layer1[i], input_shape = input_shape, activation = \"relu\" ))\n",
        "    model.add(Dense(50, activation = ))\n",
        "    model.add(Dense(num_classes, activation = 'softmax'))\n",
        "    \n",
        "    # Glove\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "    model.fit(X_train_g, y_train_g, epochs = 15, batch_size = 200)\n",
        "    test_results = model.evaluate(X_test_g, y_test_g)\n",
        "    acc_g.append(test_results[1])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KZ3NHaN97Fh"
      },
      "source": [
        "\n",
        "plt.plot(num_layer2, acc_w2v, color = \"red\", label = \"Word 2 Vec\")\n",
        "plt.plot(num_layer2, acc_g, color = \"blue\", label = \"Glove\")\n",
        "plt.title(\"Accuracy with Layer 2 sizes\")\n",
        "plt.xlabel(\"Layer 2 sizes\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yZ_FCOsvF0W"
      },
      "source": [
        "# Final Best Model\n",
        "# Glove outperforms Word2Vec\n",
        "# Word2Vec\n",
        "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_w2v, y, test_size = 0.20)\n",
        "\n",
        "model_w2v = Sequential()\n",
        "model_w2v.add(Dense(400, input_shape = input_shape, activation = \"relu\" ))\n",
        "model_w2v.add(Dense(50, activation = \"relu\" ))\n",
        "model_w2v.add(Dense(num_classes, activation = 'softmax'))\n",
        "    \n",
        "# Word2vec\n",
        "model_w2v.compile(loss = 'categorical_crossentropy', optimizer = 'RMSprop', metrics = ['accuracy'])\n",
        "model_w2v.fit(X_train_w2v, y_train_w2v, epochs = 30, batch_size = 200)\n",
        "test_results_w2v = model_w2v.evaluate(X_test_w2v, y_test_w2v)\n",
        "print(f'Test results - Loss: {test_results_w2v[0]} - Accuracy: {test_results_w2v[1]}%')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY-85SiZvPB1"
      },
      "source": [
        "# Glove Best Model\n",
        "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(X_g, y, test_size = 0.20)\n",
        "\n",
        "model_g = Sequential()\n",
        "model_g.add(Dense(400, input_shape = input_shape, activation = \"relu\" ))\n",
        "model_g.add(Dense(50, activation = \"relu\" ))\n",
        "model_g.add(Dense(num_classes, activation = 'softmax'))\n",
        "    \n",
        "# Glove\n",
        "model_g.compile(loss = 'categorical_crossentropy', optimizer = 'RMSprop', metrics = ['accuracy'])\n",
        "model_g.fit(X_train_g, y_train_g, epochs = 30, batch_size = 200)\n",
        "test_results_g = model_g.evaluate(X_test_g, y_test_g)\n",
        "print(f'Test results - Loss: {test_results_g[0]} - Accuracy: {test_results_g[1]}%')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYL_fRrxZ8Kr"
      },
      "source": [
        "from prettytable import PrettyTable \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MLjo_P3uSzI"
      },
      "source": [
        "# Cross Validation\n",
        "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZQIVzttCl9x"
      },
      "source": [
        "# Cross Validation\n",
        "kfold = RepeatedKFold(n_splits = 3, n_repeats = 1)\n",
        "\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(X_w2v, y):\n",
        "    model = buildmodel(input_shape)\n",
        "    history = model.fit(X_w2v[train], y[train],\n",
        "              batch_size = 200,\n",
        "              epochs = 15,\n",
        "              verbose = 0)\n",
        "    \n",
        "    y_pred = model.predict(X_w2v[test])\n",
        "    y_pred = np.argmax(y_pred, axis = 1)\n",
        "    y_pred = le.inverse_transform(y_pred)\n",
        "    y = le.inverse_transform(y)\n",
        "    print(\"for Fold Number\", fold_no)\n",
        "    \n",
        "    d, mx = cf_matrix(y_pred, y[test])\n",
        "    print(\"The precision score is\")\n",
        "    precision(d, mx)\n",
        "\n",
        "    print(\"The recall score is\")\n",
        "    recall(d, mx)\n",
        "\n",
        "    print(\"The F1-score is\") \n",
        "    f1score(d, mx)\n",
        "\n",
        "    print(\"Total precision recall and F1 score is\")\n",
        "    \n",
        "    print(precision_recall_fscore_support(y_pred, y[test], average = 'weighted'))\n",
        "    y = le.fit_transform(y)\n",
        "    fold_no += 1\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nIMPIJlJgLL"
      },
      "source": [
        "def buildmodel(input_shape):\n",
        "    model= Sequential([\n",
        "        Dense(400, input_shape = input_shape, activation = \"relu\" ),\n",
        "        Dense(50, activation = \"relu\" ),\n",
        "        Dense(num_classes, activation = 'softmax')\n",
        "    ])\n",
        "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'RMSprop', metrics = ['accuracy'])\n",
        "    return(model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VttBMq9UuU4W"
      },
      "source": [
        "# KFold Cross Validation\n",
        "# Glove\n",
        "kfold = RepeatedKFold(n_splits = 3, n_repeats = 1)\n",
        "\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(X_g, y):\n",
        "    model = buildmodel(input_shape)\n",
        "    history = model.fit(X_g[train], y[train],\n",
        "              batch_size = 200,\n",
        "              epochs = 15,\n",
        "              verbose = 0)\n",
        "    \n",
        "    y_pred = model.predict(X_g[test])\n",
        "    y_pred = np.argmax(y_pred, axis = 1)\n",
        "    y_pred = le.inverse_transform(y_pred)\n",
        "    y = le.inverse_transform(y)\n",
        "    print(\"for Fold Number\", fold_no)\n",
        "    \n",
        "    d, mx = cf_matrix(y_pred, y[test])\n",
        "    print(\"The precision score is\")\n",
        "    precision(d, mx)\n",
        "\n",
        "    print(\"The recall score is\")\n",
        "    recall(d, mx)\n",
        "\n",
        "    print(\"The F1-score is\") \n",
        "    f1score(d, mx)\n",
        "\n",
        "    print(\"Total precision recall and F1 score is\")\n",
        "    \n",
        "    print(precision_recall_fscore_support(y_pred, y[test], average = 'weighted'))\n",
        "    y = le.fit_transform(y)\n",
        "    fold_no += 1\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFcDJeDpZ2Ty"
      },
      "source": [
        "def cf_matrix(pred_tags,test_tags):\n",
        "  head = ['PRON','VERB','ADP','DET','ADJ','NOUN','.','ADV','CONJ','X','PRT','NUM', '']\n",
        "  myTable = PrettyTable(head)\n",
        "  i=0\n",
        "  d={}\n",
        "  for wd in head:\n",
        "    d[wd]=i\n",
        "    i+=1\n",
        "  mx=[]\n",
        "  for i in range(13):\n",
        "    mx.append([0]*13)\n",
        "  print(d)\n",
        "\n",
        "  for i in range(len(test_tags)):\n",
        "    gt = test_tags[i]\n",
        "    pred = pred_tags[i]\n",
        "    mx[d[gt]][d[pred]] += 1\n",
        "  for row in mx:\n",
        "    myTable.add_row(row)\n",
        "  print(myTable)\n",
        "  return d,mx\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddnALmyfaYRp"
      },
      "source": [
        "def recall(d,mx):\n",
        "  for tag,dex in d.items():\n",
        "    print(\"Recall of tag \"+tag+\" is:\")\n",
        "    if sum(mx[:][dex]) == 0:\n",
        "        print(0)\n",
        "    else:\n",
        "        ans = round(mx[dex][dex]/sum(mx[:][dex]),2)\n",
        "        print(ans)\n",
        "\n",
        "def precision(d,mx):\n",
        "  for tag,dex in d.items():\n",
        "    print(\"Precision of tag \"+tag+\" is:\")\n",
        "    if sum(mx[:][dex]) == 0:\n",
        "        print(0)\n",
        "    else:\n",
        "        ans = round(mx[dex][dex]/sum(mx[dex][:]),2)\n",
        "        print(ans)\n",
        "\n",
        "def f1score(d,mx):\n",
        "  for tag,dex in d.items():\n",
        "    print(\"F1 score of tag \"+tag+\" is:\")\n",
        "    if (sum(mx[dex][:]) == 0) or (sum(mx[:][dex]) == 0):\n",
        "        print(0)\n",
        "    else:\n",
        "        p = round(mx[dex][dex]/sum(mx[dex][:]),2)\n",
        "        r = round(mx[dex][dex]/sum(mx[:][dex]),2)\n",
        "\n",
        "        if (p+r) == 0:\n",
        "            print(0)\n",
        "        else:\n",
        "            print(2*p*r/(p+r))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}